#!/usr/bin/env python3
"""
microservices-wiki ãƒšãƒ¼ã‚¸å“è³ªãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼

ç”Ÿæˆã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ Wiki ãƒšãƒ¼ã‚¸ãŒå“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
deepwiki ã® validate_page.py ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Wikiç‰¹æœ‰ã®åŸºæº–ã‚’è¿½åŠ ã€‚

ä½¿ç”¨æ–¹æ³•:
  python validate_arch_page.py <ãƒšãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«.md> [--importance high|medium|low]
  python validate_arch_page.py <arch-wikiãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª> [--scale small|medium|large]
"""

import sys
import re
import os
import json
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional


@dataclass
class ValidationResult:
    """1ãƒšãƒ¼ã‚¸ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ"""
    file: str
    importance: str
    score: int = 0
    max_score: int = 0
    issues: list = field(default_factory=list)
    passes: list = field(default_factory=list)

    @property
    def grade(self) -> str:
        pct = (self.score / self.max_score * 100) if self.max_score > 0 else 0
        if pct >= 90:
            return "A"
        elif pct >= 75:
            return "B"
        elif pct >= 60:
            return "C"
        elif pct >= 40:
            return "D"
        else:
            return "F"

    @property
    def percentage(self) -> float:
        return (self.score / self.max_score * 100) if self.max_score > 0 else 0


# --- å“è³ªåŸºæº–å®šç¾© ---
REQUIREMENTS = {
    "high": {
        "min_words": 1200,
        "min_mermaid": 2,
        "min_mermaid_types": 2,
        "min_code_snippets": 5,
        "min_sources_lines": 4,
        "sources_need_line_numbers": True,
        "min_sections": 4,
        "min_tables": 1,
    },
    "medium": {
        "min_words": 600,
        "min_mermaid": 1,
        "min_mermaid_types": 1,
        "min_code_snippets": 3,
        "min_sources_lines": 3,
        "sources_need_line_numbers": True,
        "min_sections": 3,
        "min_tables": 0,
    },
    "low": {
        "min_words": 300,
        "min_mermaid": 1,
        "min_mermaid_types": 1,
        "min_code_snippets": 1,
        "min_sources_lines": 2,
        "sources_need_line_numbers": True,
        "min_sections": 2,
        "min_tables": 0,
    },
    "index": {
        "min_words": 200,
        "min_mermaid": 1,
        "min_mermaid_types": 1,
        "min_code_snippets": 0,
        "min_sources_lines": 0,
        "sources_need_line_numbers": False,
        "min_sections": 2,
        "min_tables": 1,
    },
}

MAX_ACCEPTABLE_LINE_RANGE = 200

# ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Wikiç‰¹æœ‰: ã‚µãƒ¼ãƒ“ã‚¹åã¨ã—ã¦æ±ç”¨çš„ã™ãã‚‹åå‰
GENERIC_SERVICE_NAMES = {
    'ServiceA', 'ServiceB', 'ServiceC',
    'service-a', 'service-b', 'service-c',
    'Service', 'Microservice', 'Backend', 'Frontend',
    'API', 'Client', 'Server', 'Database', 'Cache',
    'Component', 'Module', 'System',
}


def count_words(text: str) -> int:
    """æ—¥æœ¬èª+è‹±èªã®æ··åˆãƒ†ã‚­ã‚¹ãƒˆã®èªæ•°ã‚’æ¨å®š"""
    cleaned = re.sub(r'```[\s\S]*?```', '', text)
    cleaned = re.sub(r'[#|>\-*`\[\]()]', ' ', cleaned)
    jp_chars = len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', cleaned))
    en_words = len(re.findall(r'[a-zA-Z]+', cleaned))
    return jp_chars + en_words


def count_mermaid_diagrams(text: str) -> int:
    return len(re.findall(r'```mermaid', text))


def get_mermaid_types(text: str) -> set:
    types = set()
    mermaid_blocks = re.findall(r'```mermaid\n([\s\S]*?)```', text)
    for block in mermaid_blocks:
        first_line = block.strip().split('\n')[0].strip().lower()
        if first_line.startswith('graph'):
            types.add('graph')
        elif first_line.startswith('flowchart'):
            types.add('flowchart')
        elif first_line.startswith('sequencediagram'):
            types.add('sequenceDiagram')
        elif first_line.startswith('classdiagram'):
            types.add('classDiagram')
        elif first_line.startswith('statediagram'):
            types.add('stateDiagram')
        elif first_line.startswith('erdiagram'):
            types.add('erDiagram')
        else:
            types.add('other')
    return types


def count_code_snippets(text: str) -> int:
    """Mermaid ä»¥å¤–ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    all_blocks = re.findall(r'```(\w*)', text)
    return sum(1 for lang in all_blocks if lang and lang != 'mermaid')


def count_snippet_citations(text: str) -> int:
    """ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆå†…ã®å‡ºå…¸ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    code_blocks = re.findall(r'```\w+\n([\s\S]*?)```', text)
    citations = 0
    for block in code_blocks:
        # path:Lè¡Œç•ªå· å½¢å¼ã€ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«å: å½¢å¼
        if re.search(r'(#|//|--)\s*\S+\.(ya?ml|tf|json|sql|conf|proto|toml)\s*[:\s]', block) or \
           re.search(r'//\s*\S+\.(ts|js|py|go|rs|java)\s*[:\s]L\d+', block):
            citations += 1
    return citations


def count_tables(text: str) -> int:
    lines = text.split('\n')
    table_count = 0
    for i in range(len(lines) - 1):
        if re.match(r'\s*\|.*\|.*\|', lines[i]) and \
           re.match(r'\s*\|[\s\-:]+\|[\s\-:]+\|', lines[i + 1]):
            table_count += 1
    return table_count


def find_sources_lines(text: str) -> list:
    return re.findall(r'^.*Sources?:.*$', text, re.MULTILINE)


def check_line_numbers_in_sources(sources_lines: list) -> tuple:
    with_line_nums = 0
    with_imprecise_line_nums = 0
    without_line_nums = 0

    for line in sources_lines:
        ranges = re.findall(r'L(\d+)[-â€“]L?(\d+)', line)
        if ranges:
            precise = True
            for start, end in ranges:
                span = int(end) - int(start)
                if span > MAX_ACCEPTABLE_LINE_RANGE:
                    precise = False
                    break
            if precise:
                with_line_nums += 1
            else:
                with_imprecise_line_nums += 1
        elif re.search(r'L\d+', line):
            with_line_nums += 1
        else:
            without_line_nums += 1

    return with_line_nums, with_imprecise_line_nums, without_line_nums


def count_sections(text: str) -> int:
    return len(re.findall(r'^## ', text, re.MULTILINE))


def check_overview_paragraph(text: str) -> bool:
    lines = text.split('\n')
    found_h1 = False
    for line in lines:
        if line.startswith('# ') and not line.startswith('## '):
            found_h1 = True
            continue
        if found_h1 and line.startswith('## '):
            break
        if found_h1 and line.strip() and not line.startswith('#') and \
           not line.startswith('```') and not line.startswith('>'):
            return True
    return False


def check_related_pages(text: str) -> bool:
    return bool(re.search(r'(é–¢é€£ãƒšãƒ¼ã‚¸|Related|â† å‰|â†’ æ¬¡|å‚ç…§)', text, re.IGNORECASE))


def check_arch_specific_quality(text: str) -> tuple:
    """
    ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Wikiç‰¹æœ‰ã®å“è³ªãƒã‚§ãƒƒã‚¯:
    1. Mermaidå†…ã«ã‚µãƒ¼ãƒ“ã‚¹åã®å…·ä½“æ€§ï¼ˆæ±ç”¨åã§ãªã„ã‹ï¼‰
    2. é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãŒMermaidã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã«æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ã‹
    """
    issues = []
    passes = []
    score = 0
    max_score = 0

    # --- 1. Mermaidå†…ã®ã‚µãƒ¼ãƒ“ã‚¹åå…·ä½“æ€§ãƒã‚§ãƒƒã‚¯ (5ç‚¹) ---
    max_score += 5
    mermaid_blocks = re.findall(r'```mermaid\n([\s\S]*?)```', text)
    generic_count = 0
    specific_count = 0

    for block in mermaid_blocks:
        # ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º
        labels = re.findall(r'\[([^\]]+)\]', block)
        labels += re.findall(r'"([^"]+)"', block)
        for label in labels:
            clean = label.strip('"').strip()
            if clean in GENERIC_SERVICE_NAMES:
                generic_count += 1
            elif re.match(r'[a-zA-Z][a-zA-Z0-9_-]+-[a-zA-Z]', clean) or \
                 re.match(r'[A-Z][a-z]+[A-Z]', clean) or \
                 len(clean.split()) >= 2:
                specific_count += 1

    if specific_count > 0 and generic_count == 0:
        score += 5
        passes.append(f"âœ… Mermaidå†…ã®ã‚µãƒ¼ãƒ“ã‚¹åãŒå…·ä½“çš„: {specific_count}å€‹")
    elif specific_count > 0:
        score += 3
        issues.append(f"âš ï¸  Mermaidå†…ã«æ±ç”¨åãŒæ··åœ¨: å…·ä½“çš„{specific_count}å€‹, æ±ç”¨{generic_count}å€‹")
    elif generic_count > 0:
        score += 0
        issues.append(f"âŒ Mermaidå†…ã®ã‚µãƒ¼ãƒ“ã‚¹åãŒæ±ç”¨çš„: {generic_count}å€‹ (å®Ÿéš›ã®ã‚µãƒ¼ãƒ“ã‚¹åã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„)")
    else:
        score += 3  # MermaidãŒãªã„å ´åˆã¯ä¸­é–“ç‚¹
        passes.append("âœ… Mermaidå†…ã®ãƒ©ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯: å¯¾è±¡å¤–")

    # --- 2. é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ˜è¨˜ãƒã‚§ãƒƒã‚¯ (5ç‚¹) ---
    max_score += 5
    protocol_patterns = [
        r'\bREST\b', r'\bgRPC\b', r'\bHTTP\b', r'\bHTTPS\b',
        r'\bKafka\b', r'\bRabbitMQ\b', r'\bNATS\b', r'\bSQS\b',
        r'\bWebSocket\b', r'\bGraphQL\b', r'\bEvent\b.*\bStreaming\b',
    ]
    found_protocols = []
    for pattern in protocol_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            found_protocols.append(pattern.replace(r'\b', '').replace(r'\B', ''))

    if len(found_protocols) >= 2:
        score += 5
        passes.append(f"âœ… é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹: {', '.join(found_protocols[:3])} ç­‰")
    elif len(found_protocols) == 1:
        score += 3
        passes.append(f"âœ… é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®è¨€åŠã‚ã‚Š: {found_protocols[0]}")
    else:
        issues.append("âš ï¸  é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆREST/gRPC/Kafkaç­‰ï¼‰ã®æ˜è¨˜ãŒãªã„")

    return score, max_score, issues, passes


def detect_importance(filepath: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰importanceã‚’æ¨æ¸¬"""
    basename = os.path.basename(filepath)
    if basename == 'index.md':
        return 'index'

    match = re.match(r'(\d+)\.(\d+)', basename)
    if match:
        section = int(match.group(1))
        # System Overview (1.x) ã¨ Service Communication (2.x) ã¯ high
        if section in (1, 2):
            return 'high'
        else:
            return 'medium'

    return 'medium'


def validate_page(filepath: str, importance: Optional[str] = None) -> ValidationResult:
    """1ãƒšãƒ¼ã‚¸ã‚’æ¤œè¨¼"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    if importance is None:
        importance = detect_importance(filepath)

    reqs = REQUIREMENTS.get(importance, REQUIREMENTS['medium'])
    result = ValidationResult(file=filepath, importance=importance)

    # --- 1. èªæ•°ãƒã‚§ãƒƒã‚¯ (15ç‚¹) ---
    result.max_score += 15
    word_count = count_words(content)
    min_words = reqs['min_words']
    if word_count >= min_words:
        result.score += 15
        result.passes.append(f"âœ… èªæ•°: {word_count} (åŸºæº–: {min_words}ä»¥ä¸Š)")
    elif word_count >= min_words * 0.7:
        result.score += 8
        result.issues.append(f"âš ï¸  èªæ•°ä¸è¶³: {word_count} (åŸºæº–: {min_words}ä»¥ä¸Š)")
    else:
        result.issues.append(f"âŒ èªæ•°ä¸è¶³: {word_count} (åŸºæº–: {min_words}ä»¥ä¸Š)")

    # --- 2. Mermaidæ•° (10ç‚¹) ---
    result.max_score += 10
    mermaid_count = count_mermaid_diagrams(content)
    min_mermaid = reqs['min_mermaid']
    if mermaid_count >= min_mermaid:
        result.score += 10
        result.passes.append(f"âœ… Mermaid: {mermaid_count}å€‹ (åŸºæº–: {min_mermaid}ä»¥ä¸Š)")
    elif mermaid_count > 0:
        result.score += 5
        result.issues.append(f"âš ï¸  Mermaidä¸è¶³: {mermaid_count}å€‹ (åŸºæº–: {min_mermaid}ä»¥ä¸Š)")
    else:
        result.issues.append(f"âŒ Mermaidãªã— (åŸºæº–: {min_mermaid}ä»¥ä¸Š)")

    # --- 3. Mermaidç¨®é¡ã®å¤šæ§˜æ€§ (5ç‚¹) ---
    result.max_score += 5
    mermaid_types = get_mermaid_types(content)
    min_types = reqs['min_mermaid_types']
    if len(mermaid_types) >= min_types:
        result.score += 5
        result.passes.append(f"âœ… Mermaidç¨®é¡: {', '.join(sorted(mermaid_types))} ({len(mermaid_types)}ç¨®é¡)")
    elif len(mermaid_types) > 0:
        result.score += 2
        result.issues.append(f"âš ï¸  Mermaidç¨®é¡ä¸è¶³: {', '.join(sorted(mermaid_types))} ({len(mermaid_types)}ç¨®é¡, åŸºæº–: {min_types}ä»¥ä¸Š)")
    else:
        result.issues.append("âŒ Mermaidãªã—")

    # --- 4. ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆæ•° (15ç‚¹) ---
    result.max_score += 15
    snippet_count = count_code_snippets(content)
    min_snippets = reqs['min_code_snippets']
    if snippet_count >= min_snippets:
        result.score += 15
        result.passes.append(f"âœ… ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆ: {snippet_count}å€‹ (åŸºæº–: {min_snippets}ä»¥ä¸Š)")
    elif snippet_count > 0 and min_snippets > 0:
        partial = min(10, int(15 * snippet_count / min_snippets))
        result.score += partial
        result.issues.append(f"âš ï¸  ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆä¸è¶³: {snippet_count}å€‹ (åŸºæº–: {min_snippets}ä»¥ä¸Š)")
    elif min_snippets > 0:
        result.issues.append(f"âŒ ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆãªã— (åŸºæº–: {min_snippets}ä»¥ä¸Š, ã‚¤ãƒ³ãƒ•ãƒ©å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¼•ç”¨)")
    else:
        result.score += 15

    # --- 5. ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‡ºå…¸ã‚³ãƒ¡ãƒ³ãƒˆ (5ç‚¹) ---
    result.max_score += 5
    if snippet_count > 0:
        citation_count = count_snippet_citations(content)
        if citation_count >= snippet_count * 0.6:
            result.score += 5
            result.passes.append(f"âœ… ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‡ºå…¸: {citation_count}/{snippet_count}å€‹ã«å‡ºå…¸ã‚³ãƒ¡ãƒ³ãƒˆã‚ã‚Š")
        elif citation_count > 0:
            result.score += 2
            result.issues.append(f"âš ï¸  ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‡ºå…¸ä¸è¶³: {citation_count}/{snippet_count}å€‹ã®ã¿")
        else:
            result.issues.append("âŒ ã‚¹ãƒ‹ãƒšãƒƒãƒˆå‡ºå…¸ãªã— (# path/to/file.yml å½¢å¼ã®ã‚³ãƒ¡ãƒ³ãƒˆãŒå¿…è¦)")

    # --- 6. Sourcesè¡Œå­˜åœ¨ (10ç‚¹) ---
    result.max_score += 10
    sources_lines = find_sources_lines(content)
    min_sources = reqs['min_sources_lines']
    if len(sources_lines) >= min_sources:
        result.score += 10
        result.passes.append(f"âœ… Sourcesè¡Œ: {len(sources_lines)}è¡Œ")
    elif len(sources_lines) > 0:
        result.score += 5
        result.issues.append(f"âš ï¸  Sourcesè¡Œä¸è¶³: {len(sources_lines)}è¡Œ (åŸºæº–: {min_sources}ä»¥ä¸Š)")
    else:
        result.issues.append(f"âŒ Sourcesè¡Œãªã—")

    # --- 7. Sourcesè¡Œç•ªå·ç²¾åº¦ (10ç‚¹) ---
    result.max_score += 10
    if sources_lines and reqs['sources_need_line_numbers']:
        precise, imprecise, no_ln = check_line_numbers_in_sources(sources_lines)
        if precise > 0 and imprecise == 0 and no_ln == 0:
            result.score += 10
            result.passes.append(f"âœ… Sourcesè¡Œç•ªå·: å…¨{precise}è¡Œã«æ­£ç¢ºãªè¡Œç•ªå·ã‚ã‚Š")
        elif precise > 0:
            result.score += 7
            result.issues.append(f"âš ï¸  Sourcesè¡Œç•ªå·: æ­£ç¢º{precise}è¡Œ, ä¸æ­£ç¢º{imprecise}è¡Œ, è¡Œç•ªå·ãªã—{no_ln}è¡Œ")
        elif imprecise > 0:
            result.score += 3
            result.issues.append(f"âš ï¸  Sourcesè¡Œç•ªå·ãŒä¸æ­£ç¢º: {imprecise}è¡ŒãŒ{MAX_ACCEPTABLE_LINE_RANGE}è¡Œè¶…")
        else:
            result.issues.append("âŒ Sourcesè¡Œã«è¡Œç•ªå·ãªã— ([docker-compose.yml:L1-L45] å½¢å¼)")
    elif sources_lines:
        result.score += 5

    # --- 8. ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•° (5ç‚¹) ---
    result.max_score += 5
    section_count = count_sections(content)
    min_sections = reqs['min_sections']
    if section_count >= min_sections:
        result.score += 5
        result.passes.append(f"âœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {section_count}")
    else:
        result.issues.append(f"âš ï¸  ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸è¶³: {section_count} (åŸºæº–: {min_sections}ä»¥ä¸Š)")
        result.score += 2 if section_count > 0 else 0

    # --- 9. æ¦‚è¦æ®µè½ (5ç‚¹) ---
    result.max_score += 5
    if check_overview_paragraph(content):
        result.score += 5
        result.passes.append("âœ… æ¦‚è¦æ®µè½ã‚ã‚Š")
    else:
        result.issues.append("âŒ æ¦‚è¦æ®µè½ãªã—")

    # --- 10. é–¢é€£ãƒšãƒ¼ã‚¸ãƒªãƒ³ã‚¯ (5ç‚¹) ---
    result.max_score += 5
    if check_related_pages(content):
        result.score += 5
        result.passes.append("âœ… é–¢é€£ãƒšãƒ¼ã‚¸ãƒªãƒ³ã‚¯ã‚ã‚Š")
    else:
        result.issues.append("âš ï¸  é–¢é€£ãƒšãƒ¼ã‚¸ãƒªãƒ³ã‚¯ãªã—")

    # --- 11. ãƒ†ãƒ¼ãƒ–ãƒ« (5ç‚¹) ---
    result.max_score += 5
    table_count = count_tables(content)
    min_tables = reqs['min_tables']
    if min_tables > 0:
        if table_count >= min_tables:
            result.score += 5
            result.passes.append(f"âœ… ãƒ†ãƒ¼ãƒ–ãƒ«: {table_count}å€‹")
        elif table_count > 0:
            result.score += 2
            result.issues.append(f"âš ï¸  ãƒ†ãƒ¼ãƒ–ãƒ«ä¸è¶³: {table_count}å€‹ (åŸºæº–: {min_tables}ä»¥ä¸Š)")
        else:
            result.issues.append("âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ãªã— (ã‚µãƒ¼ãƒ“ã‚¹ä¸€è¦§ãƒ»APIä¸€è¦§ç­‰ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«ã§æ•´ç†)")
    else:
        result.score += 5 if table_count > 0 else 3

    # --- 12. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç‰¹æœ‰ãƒã‚§ãƒƒã‚¯ (10ç‚¹) ---
    arch_score, arch_max, arch_issues, arch_passes = check_arch_specific_quality(content)
    result.score += arch_score
    result.max_score += arch_max
    result.issues.extend(arch_issues)
    result.passes.extend(arch_passes)

    return result


def format_result(result: ValidationResult) -> str:
    lines = []
    basename = os.path.basename(result.file)
    lines.append(f"{'='*60}")
    lines.append(f"ğŸ“„ {basename}")
    lines.append(f"   Importance: {result.importance}  |  Grade: {result.grade}  |  Score: {result.score}/{result.max_score} ({result.percentage:.0f}%)")
    lines.append(f"{'='*60}")

    if result.issues:
        lines.append("")
        lines.append("  æ”¹å–„ãŒå¿…è¦:")
        for issue in result.issues:
            lines.append(f"    {issue}")

    if result.passes:
        lines.append("")
        lines.append("  åˆæ ¼é …ç›®:")
        for p in result.passes:
            lines.append(f"    {p}")

    lines.append("")
    return '\n'.join(lines)


def format_summary(results: list) -> str:
    lines = []
    lines.append(f"\n{'#'*60}")
    lines.append(f"  microservices-wiki å“è³ªãƒ¬ãƒãƒ¼ãƒˆ")
    lines.append(f"{'#'*60}\n")

    total_score = sum(r.score for r in results)
    total_max = sum(r.max_score for r in results)
    avg_pct = (total_score / total_max * 100) if total_max > 0 else 0

    grades = {}
    for r in results:
        g = r.grade
        grades[g] = grades.get(g, 0) + 1

    lines.append(f"  ç·åˆã‚¹ã‚³ã‚¢: {total_score}/{total_max} ({avg_pct:.0f}%)")
    lines.append(f"  ãƒšãƒ¼ã‚¸æ•°: {len(results)}")
    lines.append(f"  ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ: {', '.join(f'{g}={c}' for g, c in sorted(grades.items()))}")
    lines.append("")

    lines.append(f"  {'ãƒšãƒ¼ã‚¸':<45} {'Grade':>5}  {'Score':>10}")
    lines.append(f"  {'-'*45} {'-'*5}  {'-'*10}")
    for r in results:
        basename = os.path.basename(r.file)
        lines.append(f"  {basename:<45} {r.grade:>5}  {r.score:>3}/{r.max_score:<3} ({r.percentage:.0f}%)")

    failing = [r for r in results if r.grade in ('D', 'F')]
    if failing:
        lines.append(f"\n  âš ï¸  è¦æ”¹å–„ãƒšãƒ¼ã‚¸ ({len(failing)}ä»¶):")
        for r in failing:
            basename = os.path.basename(r.file)
            top_issues = [i for i in r.issues if i.startswith('âŒ')][:3]
            lines.append(f"    - {basename}: {', '.join(top_issues)}")

    lines.append("")
    return '\n'.join(lines)


# --- Wikiå…¨ä½“æ§‹é€ ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ ---

SCALE_GUIDELINES = {
    "small": {
        "label": "å°è¦æ¨¡ (3-5ã‚µãƒ¼ãƒ“ã‚¹)",
        "min_pages": 10,
        "max_pages": 18,
        "min_sections": 3,
        "max_sections": 5,
    },
    "medium": {
        "label": "ä¸­è¦æ¨¡ (6-15ã‚µãƒ¼ãƒ“ã‚¹)",
        "min_pages": 18,
        "max_pages": 30,
        "min_sections": 4,
        "max_sections": 6,
    },
    "large": {
        "label": "å¤§è¦æ¨¡ (16ã‚µãƒ¼ãƒ“ã‚¹ä»¥ä¸Š)",
        "min_pages": 30,
        "max_pages": 50,
        "min_sections": 5,
        "max_sections": 8,
    },
}

REQUIRED_SECTIONS = {
    1: "System Overview",
    2: "Service Communication",
    3: "Data Architecture",
    4: "Infrastructure & Deployment",
}


def validate_wiki_structure(results: list, scale: Optional[str] = None) -> dict:
    """Wikiå…¨ä½“ã®æ§‹é€ ã‚’æ¤œè¨¼"""
    page_count = len([r for r in results if os.path.basename(r.file) != 'index.md'])

    if scale is None:
        if page_count <= 18:
            scale = "small"
        elif page_count <= 30:
            scale = "medium"
        else:
            scale = "large"

    guide = SCALE_GUIDELINES[scale]
    issues = []
    passes = []
    score = 0
    max_score = 0

    # ãƒšãƒ¼ã‚¸æ•°ãƒã‚§ãƒƒã‚¯
    max_score += 20
    min_p, max_p = guide['min_pages'], guide['max_pages']
    if min_p <= page_count <= max_p:
        score += 20
        passes.append(f"âœ… ãƒšãƒ¼ã‚¸æ•°: {page_count} ({guide['label']}: {min_p}-{max_p}ãƒšãƒ¼ã‚¸)")
    elif page_count > max_p:
        score += 15
        issues.append(f"âš ï¸  ãƒšãƒ¼ã‚¸æ•°ãŒå¤šã„: {page_count} ({min_p}-{max_p}ãƒšãƒ¼ã‚¸)")
    elif page_count >= min_p * 0.7:
        score += 10
        issues.append(f"âš ï¸  ãƒšãƒ¼ã‚¸æ•°ãŒã‚„ã‚„å°‘ãªã„: {page_count} ({min_p}ãƒšãƒ¼ã‚¸ä»¥ä¸Šæ¨å¥¨)")
    else:
        issues.append(f"âŒ ãƒšãƒ¼ã‚¸æ•°ä¸è¶³: {page_count} ({min_p}ãƒšãƒ¼ã‚¸ä»¥ä¸Šå¿…è¦)")

    # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ç¢ºèª
    max_score += 30
    sections_found = set()
    for r in results:
        basename = os.path.basename(r.file)
        m = re.match(r'^(\d+)', basename)
        if m:
            sections_found.add(int(m.group(1)))

    missing = []
    for sec_num, sec_name in REQUIRED_SECTIONS.items():
        if sec_num not in sections_found:
            missing.append(f"Section {sec_num} ({sec_name})")

    if not missing:
        score += 30
        passes.append(f"âœ… å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³: å…¨ã¦å­˜åœ¨")
    else:
        score += int(30 * (len(REQUIRED_SECTIONS) - len(missing)) / len(REQUIRED_SECTIONS))
        for m_item in missing:
            issues.append(f"âŒ å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¬ è½: {m_item}")

    # Grade Bä»¥ä¸Šã®æ¯”ç‡ãƒã‚§ãƒƒã‚¯
    max_score += 20
    grade_b_plus = sum(1 for r in results if r.grade in ('A', 'B')
                       and os.path.basename(r.file) != 'index.md')
    b_ratio = grade_b_plus / page_count if page_count > 0 else 0
    if b_ratio >= 0.80:
        score += 20
        passes.append(f"âœ… Grade Bä»¥ä¸Š: {grade_b_plus}/{page_count} ({b_ratio:.0%})")
    elif b_ratio >= 0.60:
        score += 12
        issues.append(f"âš ï¸  Grade Bä»¥ä¸Šã®æ¯”ç‡ãŒä½ã„: {grade_b_plus}/{page_count} ({b_ratio:.0%}, ç›®æ¨™: 80%)")
    else:
        issues.append(f"âŒ Grade Bä»¥ä¸Šã®æ¯”ç‡ãŒä¸è¶³: {grade_b_plus}/{page_count} ({b_ratio:.0%})")

    return {
        "scale": scale,
        "page_count": page_count,
        "score": score,
        "max_score": max_score,
        "issues": issues,
        "passes": passes,
        "sections_found": sorted(sections_found),
    }


def main():
    import argparse

    parser = argparse.ArgumentParser(description='microservices-wiki ãƒšãƒ¼ã‚¸å“è³ªãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼')
    parser.add_argument('target', help='æ¤œè¨¼ã™ã‚‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--importance', choices=['high', 'medium', 'low', 'index'],
                        help='ãƒšãƒ¼ã‚¸ã®é‡è¦åº¦')
    parser.add_argument('--scale', choices=['small', 'medium', 'large'],
                        help='Wikiã®è¦æ¨¡ (ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŒ‡å®šæ™‚ã®ã¿)')
    args = parser.parse_args()

    target = Path(args.target)

    if target.is_file():
        # å˜ä¸€ãƒšãƒ¼ã‚¸ã®æ¤œè¨¼
        result = validate_page(str(target), args.importance)
        print(format_result(result))

        grade_d_f = result.grade in ('D', 'F')
        sys.exit(1 if grade_d_f else 0)

    elif target.is_dir():
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã®æ¤œè¨¼
        md_files = sorted(target.glob('*.md'))
        if not md_files:
            print(f"ERROR: Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target}")
            sys.exit(1)

        results = []
        for md_file in md_files:
            result = validate_page(str(md_file))
            print(format_result(result))
            results.append(result)

        print(format_summary(results))

        # æ§‹é€ ãƒã‚§ãƒƒã‚¯
        ws = validate_wiki_structure(results, args.scale)
        print(f"\n{'='*60}")
        print(f"  ğŸ“Š Wiki æ§‹é€ ãƒã‚§ãƒƒã‚¯ (è¦æ¨¡: {SCALE_GUIDELINES[ws['scale']]['label']})")
        print(f"{'='*60}")
        print(f"  ã‚¹ã‚³ã‚¢: {ws['score']}/{ws['max_score']} ({ws['score']/ws['max_score']*100:.0f}%)")
        print(f"  æ¤œå‡ºã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³: {ws['sections_found']}")
        print("")
        if ws['passes']:
            print("  åˆæ ¼é …ç›®:")
            for p in ws['passes']:
                print(f"    {p}")
        if ws['issues']:
            print("  æ”¹å–„ãŒå¿…è¦:")
            for i in ws['issues']:
                print(f"    {i}")
        print("")

        failing = sum(1 for r in results if r.grade in ('D', 'F'))
        sys.exit(1 if failing > 0 else 0)

    else:
        print(f"ERROR: ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {target}")
        sys.exit(1)


if __name__ == '__main__':
    main()
